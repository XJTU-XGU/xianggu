<!DOCTYPE html>
<!-- saved from url=(0046)https://ml.cs.tsinghua.edu.cn/prolificdreamer/ -->
<html class="fontawesome-i2svg-active fontawesome-i2svg-complete"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Optimal Transport-Guided Conditional Score-Based Diffusion Model</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script> -->

  <style type="text/css">svg:not(:root).svg-inline--fa{overflow:visible}.svg-inline--fa{display:inline-block;font-size:inherit;height:1em;overflow:visible;vertical-align:-.125em}.svg-inline--fa.fa-lg{vertical-align:-.225em}.svg-inline--fa.fa-w-1{width:.0625em}.svg-inline--fa.fa-w-2{width:.125em}.svg-inline--fa.fa-w-3{width:.1875em}.svg-inline--fa.fa-w-4{width:.25em}.svg-inline--fa.fa-w-5{width:.3125em}.svg-inline--fa.fa-w-6{width:.375em}.svg-inline--fa.fa-w-7{width:.4375em}.svg-inline--fa.fa-w-8{width:.5em}.svg-inline--fa.fa-w-9{width:.5625em}.svg-inline--fa.fa-w-10{width:.625em}.svg-inline--fa.fa-w-11{width:.6875em}.svg-inline--fa.fa-w-12{width:.75em}.svg-inline--fa.fa-w-13{width:.8125em}.svg-inline--fa.fa-w-14{width:.875em}.svg-inline--fa.fa-w-15{width:.9375em}.svg-inline--fa.fa-w-16{width:1em}.svg-inline--fa.fa-w-17{width:1.0625em}.svg-inline--fa.fa-w-18{width:1.125em}.svg-inline--fa.fa-w-19{width:1.1875em}.svg-inline--fa.fa-w-20{width:1.25em}.svg-inline--fa.fa-pull-left{margin-right:.3em;width:auto}.svg-inline--fa.fa-pull-right{margin-left:.3em;width:auto}.svg-inline--fa.fa-border{height:1.5em}.svg-inline--fa.fa-li{width:2em}.svg-inline--fa.fa-fw{width:1.25em}.fa-layers svg.svg-inline--fa{bottom:0;left:0;margin:auto;position:absolute;right:0;top:0}.fa-layers{display:inline-block;height:1em;position:relative;text-align:center;vertical-align:-.125em;width:1em}.fa-layers svg.svg-inline--fa{-webkit-transform-origin:center center;transform-origin:center center}.fa-layers-counter,.fa-layers-text{display:inline-block;position:absolute;text-align:center}.fa-layers-text{left:50%;top:50%;-webkit-transform:translate(-50%,-50%);transform:translate(-50%,-50%);-webkit-transform-origin:center center;transform-origin:center center}.fa-layers-counter{background-color:#ff253a;border-radius:1em;-webkit-box-sizing:border-box;box-sizing:border-box;color:#fff;height:1.5em;line-height:1;max-width:5em;min-width:1.5em;overflow:hidden;padding:.25em;right:0;text-overflow:ellipsis;top:0;-webkit-transform:scale(.25);transform:scale(.25);-webkit-transform-origin:top right;transform-origin:top right}.fa-layers-bottom-right{bottom:0;right:0;top:auto;-webkit-transform:scale(.25);transform:scale(.25);-webkit-transform-origin:bottom right;transform-origin:bottom right}.fa-layers-bottom-left{bottom:0;left:0;right:auto;top:auto;-webkit-transform:scale(.25);transform:scale(.25);-webkit-transform-origin:bottom left;transform-origin:bottom left}.fa-layers-top-right{right:0;top:0;-webkit-transform:scale(.25);transform:scale(.25);-webkit-transform-origin:top right;transform-origin:top right}.fa-layers-top-left{left:0;right:auto;top:0;-webkit-transform:scale(.25);transform:scale(.25);-webkit-transform-origin:top left;transform-origin:top left}.fa-lg{font-size:1.3333333333em;line-height:.75em;vertical-align:-.0667em}.fa-xs{font-size:.75em}.fa-sm{font-size:.875em}.fa-1x{font-size:1em}.fa-2x{font-size:2em}.fa-3x{font-size:3em}.fa-4x{font-size:4em}.fa-5x{font-size:5em}.fa-6x{font-size:6em}.fa-7x{font-size:7em}.fa-8x{font-size:8em}.fa-9x{font-size:9em}.fa-10x{font-size:10em}.fa-fw{text-align:center;width:1.25em}.fa-ul{list-style-type:none;margin-left:2.5em;padding-left:0}.fa-ul>li{position:relative}.fa-li{left:-2em;position:absolute;text-align:center;width:2em;line-height:inherit}.fa-border{border:solid .08em #eee;border-radius:.1em;padding:.2em .25em .15em}.fa-pull-left{float:left}.fa-pull-right{float:right}.fa.fa-pull-left,.fab.fa-pull-left,.fal.fa-pull-left,.far.fa-pull-left,.fas.fa-pull-left{margin-right:.3em}.fa.fa-pull-right,.fab.fa-pull-right,.fal.fa-pull-right,.far.fa-pull-right,.fas.fa-pull-right{margin-left:.3em}.fa-spin{-webkit-animation:fa-spin 2s infinite linear;animation:fa-spin 2s infinite linear}.fa-pulse{-webkit-animation:fa-spin 1s infinite steps(8);animation:fa-spin 1s infinite steps(8)}@-webkit-keyframes fa-spin{0%{-webkit-transform:rotate(0);transform:rotate(0)}100%{-webkit-transform:rotate(360deg);transform:rotate(360deg)}}@keyframes fa-spin{0%{-webkit-transform:rotate(0);transform:rotate(0)}100%{-webkit-transform:rotate(360deg);transform:rotate(360deg)}}.fa-rotate-90{-webkit-transform:rotate(90deg);transform:rotate(90deg)}.fa-rotate-180{-webkit-transform:rotate(180deg);transform:rotate(180deg)}.fa-rotate-270{-webkit-transform:rotate(270deg);transform:rotate(270deg)}.fa-flip-horizontal{-webkit-transform:scale(-1,1);transform:scale(-1,1)}.fa-flip-vertical{-webkit-transform:scale(1,-1);transform:scale(1,-1)}.fa-flip-both,.fa-flip-horizontal.fa-flip-vertical{-webkit-transform:scale(-1,-1);transform:scale(-1,-1)}:root .fa-flip-both,:root .fa-flip-horizontal,:root .fa-flip-vertical,:root .fa-rotate-180,:root .fa-rotate-270,:root .fa-rotate-90{-webkit-filter:none;filter:none}.fa-stack{display:inline-block;height:2em;position:relative;width:2.5em}.fa-stack-1x,.fa-stack-2x{bottom:0;left:0;margin:auto;position:absolute;right:0;top:0}.svg-inline--fa.fa-stack-1x{height:1em;width:1.25em}.svg-inline--fa.fa-stack-2x{height:2em;width:2.5em}.fa-inverse{color:#fff}.sr-only{border:0;clip:rect(0,0,0,0);height:1px;margin:-1px;overflow:hidden;padding:0;position:absolute;width:1px}.sr-only-focusable:active,.sr-only-focusable:focus{clip:auto;height:auto;margin:0;overflow:visible;position:static;width:auto}.svg-inline--fa .fa-primary{fill:var(--fa-primary-color,currentColor);opacity:1;opacity:var(--fa-primary-opacity,1)}.svg-inline--fa .fa-secondary{fill:var(--fa-secondary-color,currentColor);opacity:.4;opacity:var(--fa-secondary-opacity,.4)}.svg-inline--fa.fa-swap-opacity .fa-primary{opacity:.4;opacity:var(--fa-secondary-opacity,.4)}.svg-inline--fa.fa-swap-opacity .fa-secondary{opacity:1;opacity:var(--fa-primary-opacity,1)}.svg-inline--fa mask .fa-primary,.svg-inline--fa mask .fa-secondary{fill:#000}.fad.fa-inverse{color:#fff}</style><link href="./otcs/css" rel="stylesheet">

  <link rel="stylesheet" href="./otcs/bulma.min.css">
  <link rel="stylesheet" href="./otcs/bulma-carousel.min.css">
  <link rel="stylesheet" href="./otcs/bulma-slider.min.css">
  <link rel="stylesheet" href="./otcs/fontawesome.all.min.css">
  <link rel="stylesheet" href="./otcs/academicons.min.css">
  <link rel="stylesheet" href="./otcs/index.css">
  <!-- <link rel="icon" href="https://ml.cs.tsinghua.edu.cn/prolificdreamer/static/images/favicon.svg"> -->

  <script src="./otcs/jquery.min.js.下载"></script>
  <script defer="" src="./otcs/fontawesome.all.min.js.下载"></script>
  <script src="./otcs/bulma-carousel.min.js.下载"></script>
  <script src="./otcs/bulma-slider.min.js.下载"></script>
  <script src="./otcs/index.js.下载"></script>
  <script src="./otcs/mathjax-config.js" defer></script>
  <script type="text/javascript" id="MathJax-script" async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>


<body data-new-gr-c-s-check-loaded="14.1094.0" data-gr-ext-installed="">


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Optimal Transport-Guided Conditional Score-Based Diffusion Model (OTCS)</h1>
          <h3 class="title is-3 publication-title"></h3>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://xjtu-xgu.github.io/xianggu/">Xiang Gu</a>,</span>
            <span class="author-block">
              <a href=" ">Liwei Yang</a>,</span>
            <span class="author-block">
              <a href="http://gr.xjtu.edu.cn/web/jiansun">Jian Sun</a>,
            </span>
            <span class="author-block">
              <a href="http://gr.xjtu.edu.cn/web/zbxu">Zongben Xu</a>,
            </span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block">Xi'an Jiaotong University,</span>
          </div>

          <div class="is-size-5 publication-authors">
            <span style="font-weight: bold;">NeurIPS 2023</span>
          </div>
          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://openreview.net/forum?id=9Muli2zoFn" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <svg class="svg-inline--fa fa-file-pdf fa-w-12" aria-hidden="true" focusable="false" data-prefix="fas" data-icon="file-pdf" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512" data-fa-i2svg=""><path fill="currentColor" d="M181.9 256.1c-5-16-4.9-46.9-2-46.9 8.4 0 7.6 36.9 2 46.9zm-1.7 47.2c-7.7 20.2-17.3 43.3-28.4 62.7 18.3-7 39-17.2 62.9-21.9-12.7-9.6-24.9-23.4-34.5-40.8zM86.1 428.1c0 .8 13.2-5.4 34.9-40.2-6.7 6.3-29.1 24.5-34.9 40.2zM248 160h136v328c0 13.3-10.7 24-24 24H24c-13.3 0-24-10.7-24-24V24C0 10.7 10.7 0 24 0h200v136c0 13.2 10.8 24 24 24zm-8 171.8c-20-12.2-33.3-29-42.7-53.8 4.5-18.5 11.6-46.6 6.2-64.2-4.7-29.4-42.4-26.5-47.8-6.8-5 18.3-.4 44.1 8.1 77-11.6 27.6-28.7 64.6-40.8 85.8-.1 0-.1.1-.2.1-27.1 13.9-73.6 44.5-54.5 68 5.6 6.9 16 10 21.5 10 17.9 0 35.7-18 61.1-61.8 25.8-8.5 54.1-19.1 79-23.2 21.7 11.8 47.1 19.5 64 19.5 29.2 0 31.2-32 19.7-43.4-13.9-13.6-54.3-9.7-73.6-7.2zM377 105L279 7c-4.5-4.5-10.6-7-17-7h-6v128h128v-6.1c0-6.3-2.5-12.4-7-16.9zm-74.1 255.3c4.1-2.7-2.5-11.9-42.8-9 37.1 15.8 42.8 9 42.8 9z"></path></svg><!-- <i class="fas fa-file-pdf"></i> Font Awesome fontawesome.com -->
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2311.01226" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://neurips.cc/media/neurips-2023/Slides/72603_v3mI6NO.pdf" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <svg class="svg-inline--fa fa-file-powerpoint fa-w-12" aria-hidden="true" focusable="false" data-prefix="fas" data-icon="file-powerpoint" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512" data-fa-i2svg=""><path fill="currentColor" d="M193.7 271.2c8.8 0 15.5 2.7 20.3 8.1 9.6 10.9 9.8 32.7-.2 44.1-4.9 5.6-11.9 8.5-21.1 8.5h-26.9v-60.7h27.9zM377 105L279 7c-4.5-4.5-10.6-7-17-7h-6v128h128v-6.1c0-6.3-2.5-12.4-7-16.9zm-153 31V0H24C10.7 0 0 10.7 0 24v464c0 13.3 10.7 24 24 24h336c13.3 0 24-10.7 24-24V160H248c-13.2 0-24-10.8-24-24zm53 165.2c0 90.3-88.8 77.6-111.1 77.6V436c0 6.6-5.4 12-12 12h-30.8c-6.6 0-12-5.4-12-12V236.2c0-6.6 5.4-12 12-12h81c44.5 0 72.9 32.8 72.9 77z"></path></svg><!-- <i class="fas fa-file-powerpoint"></i> Font Awesome fontawesome.com -->
                  </span>
                  <span>Slides</span>
                </a>
              </span>
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/XJTU-XGU/OTCS/tree/main" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <svg class="svg-inline--fa fa-github fa-w-16" aria-hidden="true" focusable="false" data-prefix="fab" data-icon="github" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512" data-fa-i2svg=""><path fill="currentColor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg><!-- <i class="fab fa-github"></i> Font Awesome fontawesome.com -->
                  </span>
                  <span>Code</span>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            This paper investigates the conditional score-based diffusion model for unpaired or partially paired data. We build the first conditional score-based model, OTCS, for unpaired data. It can be used in real-world unpaired image-restoration, unpaired cross-modal medical image translation, unpaired text-to-image generation, etc. For simplicity, we take the unpaired image super-resolution as example to introduce our method.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<hr>
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <h2 class="title is-3">Unpaired Super-resolution Problem</h2>
      <p></p>
    </div>

    <div class="content has-text-justified">
      <p>In unpaired super-resolution, we are provided two sets of images of low-resolution and high-resolution, respectively. In traditional paired super-resolution, the low-resolution and high-resolution images are one-to-one paired. By contrast, in unpaired super-resolution, there lacks coupling relationship (e.g., one-to-one relationship) between low-resolution and high-resolution images (see the figures below). Unpaired super-resolution is more realistic in real-world applications, because collecting one-to-one paired images with the same content is not easy. </p>
    </div>

    <div class="columns is-centered has-text-centered">
      <div class="column">
        <div class="columns is-centered has-text-centered">
          <div class="column content">
            <a href="./otcs/figures/images.png"><img src="./otcs/figures/images.png" alt="./otcs/figures/images.png" width="700px"></a>
          </div>
        </div>
      </div>
    </div>

    <div class="content has-text-justified">
      <p>The goal of unpaired super-resolution is to train an AI model using the unpaired datasets such that it can output the high-resolution image for a test low-resolution image in inference. </p>
    </div>

    </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <h2 class="title is-3">Overall Framework of OTCS</h2>
      <p></p>
    </div>

    <div class="columns is-centered has-text-centered">
      <div class="column">
        <div class="columns is-centered has-text-centered">
          <div class="column content">
            <a href="./otcs/figures/OT_guided_SBDMs1.png"><img src="./otcs/figures/OT_guided_SBDMs1.png" alt="./otcs/figures/OT_guided_SBDMs1.png" width="1000px"></a>
          </div>
        </div>
      </div>
    </div>

    </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <h2 class="title is-3">Stage I: Building Coupling Relation Using Optimal Transport</h2>
    </div>

    <div class="content has-text-justified">
      <p>
        Since the coupling relationship between low-resolution and high-resolution images are unpaired, we build the coupling relationship using optimal transport. We denote low-resolution images as $\{{x}_i\}_{i=1}^m$ and high-resolution images as $\{{y}_j\}_{j=1}^n$. We use the dual formulation of optimal transport to learn the coupling relationship. Specifically, we train two neural networks $u_{\omega}$ and $v_{\omega}$ using the loss
      </p>

      <p>
        $$\min_{\omega}\mathcal{F}_{\rm OT}\left(u_\omega,v_\omega\right)=\frac{1}{m}\sum_{i}{u_\omega({x}_i)}+\frac{1}{n}\sum_{j}{v_\omega({y}_j)}-\frac{1}{mn}\sum_{ij}{\frac{1}{4\epsilon}\left[\left(u_\omega\left({x}_i\right)+v_\omega\left({y}_j\right)-c\left({x}_i,{y}_j\right)\right)_+\right]^2}.$$ 
      </p>

      Using the trained model, the can compute the compatibility function $H({x}_i,{y}_j)$ by
      
      $$ H\left(x_i,y_j\right)=\frac{1}{2\epsilon}\left(u_\omega\left(x_i\right)+v_\omega\left(y_j\right)-c\left(x_i,y_j\right)\right)_+. $$

      $H({x}_i,{y}_j)$ models the coupling relationship between ${x}_i,{y}_j$. Using $H$, the optimal transport plan is given by $\hat{\pi}\left(x_i,y_j\right)=\frac{1}{mn}H\left(x_i,y_j\right)$. The images with $H>0$ are coupled. We show the coupled images are below.
    </div>

    <div class="columns is-centered has-text-centered">
      <div class="column">
        <div class="columns is-centered has-text-centered">
          <div class="column content">
            <a href="./otcs/figures/guided_images.png"><img src="./otcs/figures/guided_images.png" alt="./otcs/figures/guided_images.png" width="800px"></a>
            <p>Coupled images ($H>0$) buided using optimal transport</p>
          </div>
        </div>
      </div>
    </div>


</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <h2 class="title is-3">Stage II: Training Conditional Score-Based Model</h2>
    </div>

    <div class="content has-text-justified">
      <p> For any $x_i$, we compute the compatibility function values $H({x}_i,{y}_j)$ for all the high-resolution images $\left\{y_j\right\}_{j=1}^n$. According to the compatibility function values, the coupling relationship value $\hat{\pi}\left(x_i,y_j\right)$ of all high-resolution images $\left\{y_j\right\}_{j=1}^n$ and the degraded image $x_i$ is obtained. Then, we randomly choose a high-resolution image $y_i$ from $\hat{\pi}\left(x_i,y_j\right)$ with probability of $\hat{\pi}(x_i,\cdot)$. Taking $y_i$ as the initial value, we utilize the forward stochastic differential equation $dy_t=f\left(y_t,t\right)dt+g\left(t\right)dw$ to produce noisy images, where $w$ is the Wiener process parameter, $t$ is time, and the transition probability from time 0 to time $t$ is $p_{0t}(y|y_i)$. The noisy image $y_{i,t}$ is obtained by sampling according to the transition probability $p_{0t}(y|y_i)$. We train the conditional score-based model using the conditional denoising score matching loss:
      </p>

      <p> $$\mathcal{J}_{\rm CDSM}\left(\theta\right)=\frac{1}{m}\sum_{i}\Vert s_{\theta}(y_{i,t}|x_i,t)-\nabla\log p_{0t}(y_{i,t}|y_i)\Vert_2^2.$$  </p>
    </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <h2 class="title is-3">Generating Samples in Inference</h2>
    </div>
    <div class="content has-text-justified">
      <p> With the trained conditional score-based model, we can generate samples as follows in inference. Given the degraded image $x$ to be restored in inference, the noisy image $y_M$ corresponding to the degraded image can be obtained by sampling from the transition probability $p_{0M}(y|x)$. We take $y_M$ as the initial value, and perform the reverse stochastic differential equation $dy_t=\left[f\left(y_t,t\right)-g^2\left(t\right)s_\theta\left(y_t\middle| x,t\right)\right]dt+g\left(t\right)d\bar{w}$ to generate the corresponding restored image of $x$.
      </p>
    </div>

    <p>We show the generated images as follows.</p>
     

    <div class="columns is-centered has-text-centered">
      <div class="column">
        <div class="columns is-centered has-text-centered">
          <div class="column content">
            <a href="./otcs/figures/qualitative_results_celeba.png"><img src="./otcs/figures/qualitative_results_celeba.png" alt="./otcs/figures/qualitative_results_celeba.png" width="600px"></a>
            <p>The generated images using our method OTCS.</p>
          </div>
        </div>
      </div>
    </div>
    
</section>




<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@inproceedings{
      Gu2023optimal,
      title={Optimal Transport-Guided Conditional Score-Based Diffusion Model},
      author={Gu, Xiang and Yang, Liwei and Sun, Jian and Xu, Zongben},
      booktitle={NeurIPS},
      year={2023}
      }
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">

    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>This website is constructed using the source code provided by <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>, and we are grateful for their template.</p>
        </div>
      </div>
    </div>
  </div>
</footer>



</body><grammarly-desktop-integration data-grammarly-shadow-root="true"></grammarly-desktop-integration></html>